{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import import_ipynb\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../\"))  # Go up one level and into 'data'\n",
    "from data_synthesis.benchmark_functions import *  # Import function and class\n",
    "from data_synthesis.loss_functions import *  # Import function and class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the limits of the input itself, like in a function that depends on x we limit it from [0, 1].\n",
    "# It only sets the grid of the space, IT HAS NO PROPERTIES*.\n",
    "#class TargetSpace:\n",
    "#class SampleSpace:\n",
    "#class OriginalSpace:\n",
    "class ConcreteSpace:\n",
    "    def __init__(self, space_shape, limits, sample_method=\"same\"):\n",
    "        assert len(space_shape) == len(limits), \"Each dimension must have corresponding limits\"\n",
    "        \n",
    "        self.space_shape = space_shape\n",
    "        self.limits = np.array(limits)\n",
    "        self.sample_method = sample_method\n",
    "        self.space = None  # Stores sampled points\n",
    "        self.grid = None   # Stores full grid of combinations\n",
    "        self.samples = None\n",
    "\n",
    "    def generate_space(self):\n",
    "        if self.sample_method == \"same\":\n",
    "            # Create equally spaced points per dimension\n",
    "            self.space = [np.linspace(low, high, num) for (low, high), num in zip(self.limits, self.space_shape)]\n",
    "        elif self.sample_method == \"monte_carlo\":\n",
    "            # Create random sampled points per dimension\n",
    "            self.space = [np.random.uniform(low, high, num) for (low, high), num in zip(self.limits, self.space_shape)]\n",
    "        else:\n",
    "            raise ValueError(\"Invalid sample_method. Choose 'same' or 'monte_carlo'.\")\n",
    "        \n",
    "    def generate_grid(self):\n",
    "        if self.space is None:\n",
    "            raise RuntimeError(\"Space must be generated first. Call generate_space()\")\n",
    "\n",
    "        # Generate all possible combinations of points in all dimensions\n",
    "        self.grid = np.array(list(itertools.product(*self.space)))\n",
    "\n",
    "    def get_space(self):\n",
    "        return self.space\n",
    "    \n",
    "    def get_grid(self):\n",
    "        if self.grid is None:\n",
    "            raise RuntimeError(\"Grid has not been generated. Call generate_space() first.\")\n",
    "        return self.grid\n",
    "\n",
    "    def change(self, new_shape=None, new_limits=None, new_method=None):\n",
    "        if new_shape:\n",
    "            assert len(new_shape) == len(self.limits), \"New shape must match dimensions of limits\"\n",
    "            self.space_shape = new_shape\n",
    "        if new_limits:\n",
    "            assert len(new_limits) == len(self.space_shape), \"New limits must match number of dimensions\"\n",
    "            self.limits = np.array(new_limits)\n",
    "        if new_method:\n",
    "            assert new_method in [\"same\", \"monte_carlo\"], \"Invalid method\"\n",
    "            self.sample_method = new_method\n",
    "        \n",
    "        self.generate_space()  # Regenerate space and grid\n",
    "        \n",
    "    def generate_random_samples(self, n):\n",
    "        num_dimensions = len(self.space_shape)\n",
    "        self.samples = np.random.uniform(self.limits[:, 0], self.limits[:, 1], size=(n, num_dimensions))\n",
    "        return self.samples\n",
    "    \n",
    "    def generate_one_sample(self):\n",
    "        num_dimensions = len(self.space_shape)\n",
    "        sample = np.random.uniform(self.limits[:, 0], self.limits[:, 1], size=(1, num_dimensions))\n",
    "        return sample[0]\n",
    "    \n",
    "    def is_within_limits(self, sample):\n",
    "        sample = np.array(sample)\n",
    "        return np.all((sample >= self.limits[:, 0]) & (sample <= self.limits[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the parameters available for the model to sample in a linear model we may have a and b varying from [0, 1]\n",
    "# It only sets the grid of the space, IT HAS NO PROPERTIES*.\n",
    "#class DualSpace:\n",
    "#class SearchSpace:\n",
    "class AbstractSpace:\n",
    "    def __init__(self, space_shape, limits, sample_method=\"same\"):\n",
    "        assert len(space_shape) == len(limits), \"Each dimension must have corresponding limits\"\n",
    "        \n",
    "        self.space_shape = space_shape\n",
    "        self.limits = np.array(limits)\n",
    "        self.sample_method = sample_method\n",
    "        self.space = None  # Stores sampled points\n",
    "        self.grid = None   # Stores full grid of combinations\n",
    "        self.samples = None\n",
    "\n",
    "    def generate_space(self):\n",
    "        if self.sample_method == \"same\":\n",
    "            # Create equally spaced points per dimension\n",
    "            self.space = [np.linspace(low, high, num) for (low, high), num in zip(self.limits, self.space_shape)]\n",
    "        elif self.sample_method == \"monte_carlo\":\n",
    "            # Create random sampled points per dimension\n",
    "            self.space = [np.random.uniform(low, high, num) for (low, high), num in zip(self.limits, self.space_shape)]\n",
    "        else:\n",
    "            raise ValueError(\"Invalid sample_method. Choose 'same' or 'monte_carlo'.\")\n",
    "        \n",
    "    def generate_grid(self):\n",
    "        if self.space is None:\n",
    "            raise RuntimeError(\"Space must be generated first. Call generate_space()\")\n",
    "\n",
    "        # Generate all possible combinations of points in all dimensions\n",
    "        self.grid = np.array(list(itertools.product(*self.space)))\n",
    "\n",
    "    def get_space(self):\n",
    "        return self.space\n",
    "    \n",
    "    def get_grid(self):\n",
    "        if self.grid is None:\n",
    "            raise RuntimeError(\"Grid has not been generated. Call generate_space() first.\")\n",
    "        return self.grid\n",
    "\n",
    "    def change(self, new_shape=None, new_limits=None, new_method=None):\n",
    "        if new_shape:\n",
    "            assert len(new_shape) == len(self.limits), \"New shape must match dimensions of limits\"\n",
    "            self.space_shape = new_shape\n",
    "        if new_limits:\n",
    "            assert len(new_limits) == len(self.space_shape), \"New limits must match number of dimensions\"\n",
    "            self.limits = np.array(new_limits)\n",
    "        if new_method:\n",
    "            assert new_method in [\"same\", \"monte_carlo\"], \"Invalid method\"\n",
    "            self.sample_method = new_method\n",
    "        \n",
    "        self.generate_space()  # Regenerate space and grid\n",
    "        \n",
    "    def generate_random_samples(self, n):\n",
    "        num_dimensions = len(self.space_shape)\n",
    "        self.samples = np.random.uniform(self.limits[:, 0], self.limits[:, 1], size=(n, num_dimensions))\n",
    "        return self.samples\n",
    "\n",
    "    def generate_one_sample(self):\n",
    "        num_dimensions = len(self.space_shape)\n",
    "        sample = np.random.uniform(self.limits[:, 0], self.limits[:, 1], size=(1, num_dimensions))\n",
    "        return sample[0]\n",
    "    \n",
    "    def is_within_limits(self, sample):\n",
    "        sample = np.array(sample)\n",
    "        return np.all((sample >= self.limits[:, 0]) & (sample <= self.limits[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: The search space is a N dimensional space in which the parameters represent some operation in a model, the operations are the PROPERTIES attributed to\n",
    "# that search space, one search space can have many PROPERTIES, but one PROPERTY can have only be defined in the specific dimensions of that search space\n",
    "# If the AI model has the exact complexity of the object we want to understant, the search space and the sample space have the same dimension\n",
    "# If the AI model has the same property of the object we want to understant, the properties of that space are the same, in this case we have a perfect model\n",
    "# A perfect model means, given some input in the search and sample space, the output will be the same\n",
    "# With that in mind, perhaps oversized models can still not overfit if the specific output is orthogonal to the effects given by the extra parameters\n",
    "class ModelProcessor:\n",
    "    def __init__(self, model_function, loss_function, default_abstraction=None):\n",
    "        self.model_function = model_function\n",
    "        self.loss_function = loss_function\n",
    "        self.default_abstraction = default_abstraction\n",
    "\n",
    "    def process_single(self, concrete_item, abstract_item=None):\n",
    "        if abstract_item is None:\n",
    "            if self.default_abstraction is None:\n",
    "                raise ValueError(\"No abstract item provided and no default model set.\")\n",
    "            abstract_item = self.default_abstraction\n",
    "\n",
    "        return self.model_function(*concrete_item, *abstract_item)\n",
    "\n",
    "    def process_concrete_full_abstract_one(self, concrete_grid, abstract_item=None):\n",
    "        if abstract_item is None:\n",
    "            if self.default_abstraction is None:\n",
    "                raise ValueError(\"No abstract item provided and no default model set.\")\n",
    "            abstract_item = self.default_abstraction\n",
    "            \n",
    "        return [self.model_function(*concrete, *abstract_item) for concrete in concrete_grid]\n",
    "\n",
    "    def process_abstract_full_concrete_one(self, concrete_item, abstract_grid):\n",
    "        return [self.model_function(*concrete_item, *abstract) for abstract in abstract_grid]\n",
    "\n",
    "    def compare_models(self, concrete_grid, abstract_model_1, abstract_model_2, return_mean=False):\n",
    "        results_1 = self.process_concrete_full_abstract_one(concrete_grid, abstract_model_1)\n",
    "        results_2 = self.process_concrete_full_abstract_one(concrete_grid, abstract_model_2)\n",
    "\n",
    "        loss_values = [self.loss_function(r1, r2) for r1, r2 in zip(results_1, results_2)]\n",
    "        return np.mean(loss_values) if return_mean else loss_values\n",
    "    \n",
    "    def evaluate_against_target(self, concrete_grid, abstract_grid, target_model=None):\n",
    "        loss_results = []\n",
    "        \n",
    "        if target_model is None:\n",
    "            if self.default_abstraction is None:\n",
    "                raise ValueError(\"No abstract item provided and no default model set.\")\n",
    "            target_model = self.default_abstraction\n",
    "        \n",
    "        for abstract_candidate in abstract_grid:\n",
    "            loss_value = self.compare_models(concrete_grid, target_model, abstract_candidate, return_mean=True)\n",
    "            loss_results.append(loss_value)\n",
    "\n",
    "        return loss_results\n",
    "    \n",
    "    def compare_concrete_models(self, concrete_model_1, concrete_model_2, abstract_grid, return_mean=False):\n",
    "        results_1 = self.process_abstract_full_concrete_one(concrete_model_1, abstract_grid)\n",
    "        results_2 = self.process_abstract_full_concrete_one(concrete_model_2, abstract_grid)\n",
    "\n",
    "        loss_values = [self.loss_function(r1, r2) for r1, r2 in zip(results_1, results_2)]\n",
    "        return np.mean(loss_values) if return_mean else loss_values\n",
    "    \n",
    "    def compare_concrete_models_iteration(self, concrete_model_1, abstract_grid, target_model=None, return_mean=False):\n",
    "        if target_model is None:\n",
    "            if self.default_abstraction is None:\n",
    "                raise ValueError(\"No abstract item provided and no default model set.\")\n",
    "            target_model = self.default_abstraction\n",
    "            \n",
    "        results_1 = self.process_abstract_full_concrete_one(concrete_model_1, abstract_grid)    # Do not pass the grid, pass only the correct model\n",
    "        target = self.process_single(concrete_model_1, target_model)\n",
    "\n",
    "        loss_values = [self.loss_function(target, r1) for r1 in results_1]\n",
    "        return np.mean(loss_values) if return_mean else loss_values\n",
    "    \n",
    "    def evaluate_concrete_against_target(self, concrete_grid, abstract_grid, target_model=None):\n",
    "        loss_results = []\n",
    "        \n",
    "        if target_model is None:\n",
    "            if self.default_abstraction is None:\n",
    "                raise ValueError(\"No abstract item provided and no default model set.\")\n",
    "            target_model = self.default_abstraction\n",
    "        \n",
    "        for concrete_candidate in concrete_grid:\n",
    "            loss_value = self.compare_concrete_models_iteration(concrete_candidate, abstract_grid, target_model, return_mean=True)\n",
    "            loss_results.append(loss_value)\n",
    "\n",
    "        return loss_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelComparison:\n",
    "    def __init__(self, model_1, model_2, loss_function=None):\n",
    "        self.model_1 = model_1\n",
    "        self.model_2 = model_2\n",
    "        self.loss_function = loss_function\n",
    "\n",
    "    def compare_models(self, concrete_grid_1, concrete_grid_2, abstract_model_1, abstract_model_2, return_mean=False):\n",
    "        results_1 = self.model_1.process_concrete_full_abstract_one(concrete_grid_1, abstract_model_1)\n",
    "        results_2 = self.model_2.process_concrete_full_abstract_one(concrete_grid_2, abstract_model_2)\n",
    "\n",
    "        loss_values = [self.model_1.loss_function(r1, r2) for r1, r2 in zip(results_1, results_2)]\n",
    "        return np.mean(loss_values) if return_mean else loss_values\n",
    "    \n",
    "    def evaluate_against_target(self, concrete_grid_1, concrete_grid_2, abstract_grid_2, target_model=None):\n",
    "        loss_results = []\n",
    "        \n",
    "        if target_model is None:\n",
    "            if self.model_1.default_abstraction is None:\n",
    "                raise ValueError(\"No abstract item provided and no default model set.\")\n",
    "            target_model = self.model_1.default_abstraction\n",
    "        \n",
    "        for abstract_candidate in abstract_grid_2:\n",
    "            loss_value = self.compare_models(concrete_grid_1, concrete_grid_2, target_model, abstract_candidate, return_mean=True)\n",
    "            loss_results.append(loss_value)\n",
    "\n",
    "        return loss_results\n",
    "    \n",
    "    def compare_concrete_models_iteration(self, concrete_model_1, concrete_model_2, abstract_grid, target_model=None, return_mean=False):\n",
    "        if target_model is None:\n",
    "            if self.model_1.default_abstraction is None:\n",
    "                raise ValueError(\"No abstract item provided and no default model set.\")\n",
    "            target_model = self.model_1.default_abstraction\n",
    "            \n",
    "        results_1 = self.model_2.process_abstract_full_concrete_one(concrete_model_2, abstract_grid)    # Do not pass the grid, pass only the correct model\n",
    "        target = self.model_1.process_single(concrete_model_1, target_model)\n",
    "\n",
    "        loss_values = [self.model_1.loss_function(target, r1) for r1 in results_1]\n",
    "        return np.mean(loss_values) if return_mean else loss_values\n",
    "    \n",
    "    def evaluate_concrete_against_target(self, concrete_grid_1, concrete_grid_2, abstract_grid, target_model=None):\n",
    "        loss_results = []\n",
    "        \n",
    "        if target_model is None:\n",
    "            if self.model_1.default_abstraction is None:\n",
    "                raise ValueError(\"No abstract item provided and no default model set.\")\n",
    "            target_model = self.model_1.default_abstraction\n",
    "        \n",
    "        for concrete_candidate_1, concrete_candidate_2 in zip(concrete_grid_1, concrete_grid_2):\n",
    "            loss_value = self.compare_concrete_models_iteration(concrete_candidate_1, concrete_candidate_2, abstract_grid, target_model, return_mean=True)\n",
    "            loss_results.append(loss_value)\n",
    "\n",
    "        return loss_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
